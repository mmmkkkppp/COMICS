{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.io.fits as fits\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from function import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make1Expdark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dark特定の事前準備"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "処理手順  \n",
    "ダークの名前を読み込むためのリスト作成   \n",
    "ダークを特定して、データフレームに必要な情報を入れる  \n",
    "そのcsvを該当の年のフォルダに移す  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchdarkfile(year):  #first\n",
    "    basefolder = r'/mnt/e/DataFrame/'\n",
    "    allframe = pd.read_excel(basefolder + \"COM_\"+year+\".xlsx\", skiprows=0)\n",
    "    allframe.dropna(how=\"all\", axis=0)\n",
    "    darkframe = allframe[(allframe[\"DATA_TYP\"].str.contains(\"DARK\")) |\n",
    "                        (allframe[\"OBJECT2\"].str.contains(\"DARK\"))]\n",
    "    darkframe = darkframe.reset_index(drop=True)\n",
    "    darkframe.to_csv(r'/mnt/e/DataFrame/dark/darkframe_' +\n",
    "                    year + r'.csv', encoding=\"utf-8\")\n",
    "    return darkframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMAのファイルから、ダークのヘッダーを読み込み必要な情報を取得する。  \n",
    "データフレームに格納する  \n",
    "また、dark画像をdarkフォルダを作成して移動する。  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### メモ\n",
    "INS_VER 2001-09-29以降のものにしか、YSTRTがなかった  \n",
    "YSTRTの指定により、y軸のピクセル数が変わってくる  \n",
    "1なら240pixだが、40なら160pixというように"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makedarkcsv(year):\n",
    "    basefolder = r'/mnt/e/'+year + r'/'\n",
    "    darkdf = pd.DataFrame(\n",
    "        columns=[\"FRAME_ID\", \"DATE\", \"PIXTIM\", \"RRSTRT\", \"YSTRT\", \"CoAdd\", \"Q_CHEB\"])\n",
    "    darkframe = pd.read_csv(r'/mnt/e/DataFrame/dark/darkframe_' +\n",
    "                            year + r'.csv')\n",
    "    for darkfile in darkframe[\"#FRAME_ID\"]:\n",
    "        # header読み込み\n",
    "        darkfilepath = basefolder + darkfile + \".fits\"\n",
    "        darkheader = readheader(darkfilepath)\n",
    "\n",
    "        list1 = [darkheader[\"FRAMEID\"], darkheader[\"DATE-OBS\"], darkheader[\"Q_PIXTIM\"],\n",
    "                darkheader[\"Q_RRSTRT\"], darkheader[\"Q_YSTRT\"], darkheader[\"Q_CHAM\"], darkheader[\"Q_CHEB\"]]\n",
    "        add_row = pd.DataFrame([list1], columns=darkdf.columns)\n",
    "        darkdf = pd.concat([darkdf, add_row], ignore_index=True)\n",
    "        # dark画像を移動\n",
    "        os.makedirs(basefolder+r'dark', exist_ok=True)\n",
    "        shutil.move(darkfilepath, basefolder+r'dark/')\n",
    "    darkdf.to_csv(basefolder+r'dark/dark.csv', index=False, encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makedarkcsv(\"2003\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 天体画像の入力に対してdarkを特定(dfを返す)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify(obsfilename):\n",
    "    obsheader = readheader(obsfilename)\n",
    "    #年を取得\n",
    "    year = obsheader[\"DATE-OBS\"][:4]\n",
    "    #DARK.csvにアクセス\n",
    "    darkcsv = r'/mnt/e/'+year +r'/dark/dark.csv'\n",
    "    darkdf = pd.read_csv(darkcsv)\n",
    "    #一致条件を指定する\n",
    "    Q_PIXTIM = obsheader[\"Q_PIXTIM\"]\n",
    "    Q_RRSTRT = obsheader[\"Q_RRSTRT\"]\n",
    "    DATE = obsheader[\"DATE-OBS\"]\n",
    "    Q_YSTRT = obsheader[\"Q_YSTRT\"]\n",
    "    A = (darkdf[\"PIXTIM\"] == Q_PIXTIM)\n",
    "    B = (darkdf[\"RRSTRT\"] == Q_RRSTRT)\n",
    "    C = (darkdf[\"DATE\"] == DATE)\n",
    "    D = (darkdf[\"YSTRT\"] == Q_YSTRT)\n",
    "    df = darkdf[A & B & C & D].reset_index(drop=True)\n",
    "    return df, year"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特定後、1Expあたりの平均画像作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make1Expdark(obsfile):\n",
    "    df = identify(obsfile)[0]\n",
    "    year = identify(obsfile)[1]\n",
    "    darkbasefolder = r'/mnt/e/' + year +r'/dark/'\n",
    "    obsdata= readdata(obsfile)\n",
    "    #obsdataと同じshapeの0のnumpyを作成\n",
    "    darkdata = np.zeros(list(obsdata.shape))\n",
    "    if len(df) == 0:\n",
    "        print(\"該当のダークが存在しない\")\n",
    "        #ここにはその場合の処理を記載する。\n",
    "        \n",
    "    #特定したダークファイル一枚一枚に対して、Q_CHEBが同じものを抽出??\n",
    "\n",
    "    # df[df[\"Q_CHEB\"].duplicated()]\n",
    "    for darkfile in df[\"FRAME_ID\"]:\n",
    "        darkfilepath = darkbasefolder + darkfile +r'.fits'\n",
    "        darkdata += np.mean(readdata(darkfilepath),axis=1,keepdims=True)\n",
    "    #meanをとる\n",
    "    meandark = darkdata / len(df)\n",
    "    #1Expあたりに直す\n",
    "    meandark_1 = meandark / int(df[\"Q_CHEB\"][0])\n",
    "    return meandark_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function function.make1Expdark(obsfile)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make1Expdark"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検証用  \n",
    "使用するのは、2003年の11/12にとられたCOMA00042689.fitsである。HD1255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsf = r'/mnt/e/2003/COMA00042689.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m make1Expdark(obsf)\n",
      "File \u001b[0;32m/mnt/c/Users/yyush/Documents/GitHub/COMICS/function.py:75\u001b[0m, in \u001b[0;36mmake1Expdark\u001b[0;34m(obsfile)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake1Expdark\u001b[39m(obsfile):\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mprint\u001b[39m(obsfile)\n\u001b[1;32m     76\u001b[0m     df \u001b[39m=\u001b[39m identify(obsfile)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     77\u001b[0m     year \u001b[39m=\u001b[39m identify(obsfile)[\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3804\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3804\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3806\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "make1Expdark(obsf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darkfile = identify(obsfile)[0][\"FRAME_ID\"][0]\n",
    "darkfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darkbasefolder = r'/mnt/e/' + \"2003\" + r'/dark/'\n",
    "darkfile = identify(obsfile)[0][\"FRAME_ID\"][0]\n",
    "darkfilepath =darkbasefolder + darkfile + r'.fits'\n",
    "d2 = np.mean(readdata(darkfilepath),axis=1,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsdata = readdata(obsfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_array = np.zeros(list(obsdata.shape))\n",
    "d3 = empty_array + d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
